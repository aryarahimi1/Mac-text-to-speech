# ğŸ—£ï¸ Text to Speech Web App

A simple and elegant text-to-speech web application built with Streamlit that converts your text into speech using:

- macOS's builtâ€‘in `say` command (free, offline)
- ElevenLabs API (premium AI voices)
- Kokoro (local, openâ€‘weight neural TTS â€” runs entirely on your machine)

## âœ¨ Features

- Clean, modern interface (dark theme)
- Variable speed control (0.75x â†’ 2.0x)
- Multiâ€‘line text input
- Submit shows a builtâ€‘in audio player (no autoâ€‘play)
- Transcript displayed under the player with word/character counts
- Start/Stop TTS controls (Stop affects macOS `say`; player controls are separate)
- Audio saving with history page (play, download, delete)
- macOS output saved as WAV for browser compatibility (AIFF â†’ WAV conversion)
- ElevenLabs integration: enter API key and pick a voice (+ optional advanced params)
- Kokoro provider: highâ€‘quality local TTS, no API key, saves WAV

## ğŸš€ Quick Start

### Prerequisites

- macOS (required for the `say` command) OR any OS for ElevenLabs (internet required)
- Python 3.10+ recommended (Kokoro requires Python â‰¥ 3.10)
- pip package manager
- (Optional) ElevenLabs account and API key: https://elevenlabs.io

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/aryarahimi1/Mac-text-to-speech.git
   cd Mac-text-to-speech
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Run the application**
   ```bash
   streamlit run streamlit_app.py
   ```

4. **Open your browser** and navigate to `http://localhost:8501`

## ğŸ”‘ Using ElevenLabs

1. Select "ElevenLabs" as the provider.
2. Enter your ElevenLabs API key (stored only in the current session).
3. Pick a voice from your account.
4. Type your text and click Submit. The generated MP3 will be saved in `saved_audio/` and appear in Audio History.

Notes:
- Default model is `eleven_monolingual_v1`. You can optionally choose other models and tweak voice parameters in the UI.

## ğŸ§  Using Kokoro (Local, Openâ€‘weight)

1. Select "Kokoro (local open model)" as the provider.
2. Choose language (American/British English) and provide a voice ID (defaults like `af_heart`).
3. Pick your speed and enter text, then click Submit. Output is saved as WAV.

Notes:
- Requires Python 3.10+. On first use, it may download model weights; this can take a minute.
- Runs fully locally (no API key). Performance depends on your machine.

## ğŸ® Usage

1. **Choose your reading speed** from the dropdown menu:
   - 0.75x (Slower) - Good for learning or difficult text
   - 1.0x (Normal) - Standard reading speed
   - 1.25x (Faster) - Slightly quicker pace
   - 1.5x (Much Faster) - Rapid reading for familiar content
   - 2.0x (Very Fast) - Quick playback

2. **Enter your text** in the large text area (supports multiple lines)

3. **Click Submit** to start speaking at your selected speed

4. **Monitor progress** with the speaking indicator and speed display

5. **Click Stop** to interrupt speech at any time

Provider quick tips:
- Mac: free and offline; uses builtâ€‘in voices; output is WAV.
- ElevenLabs: requires API key; returns MP3; great quality and many voices.
- Kokoro: local neural TTS; no API key; returns WAV.

## ğŸ“ Project Structure

```
Mac-text-to-speech/
â”‚
â”œâ”€â”€ streamlit_app.py    # Main application file
â”œâ”€â”€ README.md           # Project documentation
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ saved_audio/        # Generated audio files + metadata.json
```

## ğŸ› ï¸ Technical Details

- Framework: Streamlit
- macOS TTS: `say -r <rate>` generates AIFF; app converts to WAV using `afconvert` for browser playback
- ElevenLabs: REST API via `requests`; returns MP3
- Kokoro: Python pipeline (KPipeline) streams audio; writes 24 kHz mono 16â€‘bit WAV
- Styling: custom CSS
- State: Streamlit session_state

## ğŸ“¦ Where files are saved

- Audio files are saved to `saved_audio/` in the app folder.
- A `metadata.json` file tracks entries for the History page.

## ğŸ§© Troubleshooting

- If the browser audio player shows â€œErrorâ€ for Mac output, regenerate after this update (files are now WAV).
- `afconvert` is part of macOS. If conversion fails, ensure youâ€™re on macOS and try installing Xcode command line tools.
- Kokoro import errors: ensure Python â‰¥ 3.10 and that requirements installed successfully. First run may download weights.

## ğŸ†• Whatâ€™s New

- Added Kokoro as a local, openâ€‘weight TTS provider (no API key)
- Updated inâ€‘app Instructions and README to reflect provider choices and usage
- Saved audio now consistently uses WAV for Mac/Kokoro and MP3 for ElevenLabs

## ğŸ”® Future Features

### ğŸ¯ ElevenLabs-Specific Ideas (future)

- [ ] **Streaming TTS**: play audio chunks as they arrive for lower latency.
- [ ] **Optimize Latency Modes**: expose `optimize_streaming_latency` presets.
- [ ] **Emotion/Style Presets**: one-click presets that map to stability/style combos.
- [ ] **Voice Cloning**: upload samples to create custom voices, then select them.
- [ ] **Pronunciation Dictionaries**: manage `pronunciation_dictionary_ids` for names/terms.
- [ ] **SSML / Prosody Controls**: finer control over pauses, emphasis, breaks.
- [ ] **Multi-language Auto-detect**: swap to multilingual models when needed.
- [ ] **History & Reproducibility**: save all generation parameters alongside audio.
- [ ] **Usage & Cost Tracking**: estimate characters/s and show monthly usage.
- [ ] **Subtitles/SRT**: align text to timestamps and export captions.
- [ ] **Batch & Queue**: process many texts and zip outputs.
- [ ] **Share Links**: signed URLs or public pages to share clips.

### ğŸš€ Advanced (providerâ€‘agnostic)

- [ ] **Word Highlighting** - Real-time word-by-word highlighting (improved sync)
- [ ] **Speech Analytics** - Reading time estimates and statistics
- [ ] **Theme Customization** - Multiple color themes and layouts
- [ ] **Keyboard Shortcuts** - Quick controls without mouse
- [ ] **API Integration** - Support for cloud TTS services (Google, AWS, Azure)
- [ ] **Language Support** - Multi-language text-to-speech
- [ ] **Plugin System** - Extensible architecture for custom features

### ğŸ”§ Technical Improvements

- [ ] **Offline Mode** - Full functionality without internet
- [ ] **Performance Optimization** - Faster loading and smoother operation
- [ ] **Error Handling** - Better error messages and recovery
- [ ] **Configuration File** - User preferences and settings persistence
- [ ] **Docker Support** - Containerized deployment option
- [ ] **Unit Tests** - Comprehensive test coverage
- [ ] **Documentation** - API docs and developer guide

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

1. Fork the project
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License

## ğŸ™ Acknowledgments

- Built with [Streamlit](https://streamlit.io/)
- Uses macOS built-in `say` command for text-to-speech
- Inspired by the need for a simple, fast text-to-speech solution

---

Made with â¤ï¸ for better accessibility and productivity
